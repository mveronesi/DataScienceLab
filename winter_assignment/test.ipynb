{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from matplotlib import pyplot as plt\n",
    "from nlp import LemmaTokenizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = pd.read_csv(\"dataset/development.csv\", index_col=\"ids\")\n",
    "df_eval = pd.read_csv(\"dataset/evaluation.csv\", index_col=\"ids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    130157\n",
       "0     94837\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rimozione colonne inutili\n",
    "Il campo flag è uguale per tutti gli esempi, il valore di user è basso per tutti i sample relativamente alla grandezza del dataset.\n",
    "Forse si potrebbe raggruppare le date (ad esempio per periodo dell'anno) e categorizzarle con one-hot vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.drop(columns=[\"date\", \"flag\", \"user\"], inplace=True)\n",
    "df_eval.drop(columns=[\"date\", \"flag\", \"user\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gestione sample duplicati\n",
    "Ci sono alcuni elementi duplicati (riga intera). Questi vengono risolti con drop_duplicates keep='first'.\n",
    "Tuttavia, solo in df_dev, ci sono alcuni tweet che si ripetono due volte con due valori di sentiment diversi. Questi vengono tenuti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.drop_duplicates(keep='first' ,inplace=True)\n",
    "df_eval.drop_duplicates(keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rimozione tweet duplicati con sentiment diverso\n",
    "c = df_dev.index.value_counts()\n",
    "c = c[c > 1]\n",
    "indexes_to_remove = c.index.values\n",
    "df_dev.drop(labels=indexes_to_remove, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document data preprocessing\n",
    "Visto che i documenti sono corti (post di social) verranno analizzati nella loro interezza (vedi slide 60 - Data Preprocessing)\n",
    "Gli step da compiere sono:\n",
    "- document splitting (non eseguito perché i documenti sono corti)\n",
    "- tokenisation (i token sono parole, documenti corti)\n",
    "- case normalization (minuscolo)\n",
    "- stopword removal\n",
    "- stemming (trasformazione parole nella loro forma base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_computation = False\n",
    "if force_computation == True or not exists(\"./Xdata.bin\"):\n",
    "    lemmaTokenizer = LemmaTokenizer(correct=False)\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', tokenizer=lemmaTokenizer)\n",
    "    vectorizer.fit(df_dev[\"text\"].values)\n",
    "    Xdata = vectorizer.transform(df_dev[\"text\"].values)\n",
    "else:\n",
    "    with open(\"./Xdata.bin\", 'rb') as f:\n",
    "        Xdata = pickle.load(f)\n",
    "Ydata = df_dev[\"sentiment\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Xdata.bin', 'wb') as f:\n",
    "    pickle.dump(Xdata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(Xdata, Ydata, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8152969494522768\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='saga')\n",
    "model.fit(Xtrain, Ytrain)\n",
    "Ypred = model.predict(Xtest)\n",
    "Ypred = np.round(Ypred, decimals=0).astype(int)\n",
    "score = f1_score(Ytest, Ypred)\n",
    "print(score)\n",
    "# score: 81.5 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8041851267803058\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC()\n",
    "model.fit(Xtrain, Ytrain)\n",
    "Ypred = model.predict(Xtest)\n",
    "score = f1_score(Ytest, Ypred)\n",
    "print(score)\n",
    "# score: 80.6 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7328954362518035\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, max_depth=20, max_features='sqrt')\n",
    "model.fit(Xtrain, Ytrain)\n",
    "Ypred = model.predict(Xtest)\n",
    "score = f1_score(Ytest, Ypred)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd86e9477a69c659a08d66b84022f5f9bd15875679eb9c1dfdd3b3f73d8a5feb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('dslab': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
